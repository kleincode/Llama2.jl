var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Llama2","category":"page"},{"location":"#Llama2","page":"Home","title":"Llama2","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Llama2.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Llama2]","category":"page"},{"location":"#Llama2.Config","page":"Home","title":"Llama2.Config","text":"Configuration of initial parameters\n\nllama2.c correspondence Config (l.19)\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.ProbIndex","page":"Home","title":"Llama2.ProbIndex","text":"Used when sorting probabilities during top-p sampling\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.RunState","page":"Home","title":"Llama2.RunState","text":"State of the transformer model. Modified during a forward pass.\n\nllama2.c correspondence: RunState (l. 50)\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.RunState-Tuple{Config}","page":"Home","title":"Llama2.RunState","text":"RunState(config::Config)\n\nInitializes the matrices in RunState based on the shapes provided in the Config.\n\nllama2.c correspondence: mallocrunstate (l. 77)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.Sampler","page":"Home","title":"Llama2.Sampler","text":"Used to store sampling parameters.\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.Sampler-Tuple{Vector{Float32}}","page":"Home","title":"Llama2.Sampler","text":"(sampler::Sampler)(logits::Vector{Float32})\n\nSample the next token (id) based on the logits and the sampler parameters.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.Sampler-Tuple{}","page":"Home","title":"Llama2.Sampler","text":"Sampler()\n\nCreate Sampler with default parameters\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.Tokenizer","page":"Home","title":"Llama2.Tokenizer","text":"Used for mapping from strings to token arrays (Int vectors) and back.\n\nllama2.c correspondence: Tokenizer (l. 372)\n\nindextotoken = vocab\ntokentoindex = sorted_vocab\nremoved maxtokenlength (not required in Julia)\nremoved byte_pieces (not required in Julia)\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.Tokenizer-Tuple{String, Int64}","page":"Home","title":"Llama2.Tokenizer","text":"Tokenizer(tokenizer_path::String, vocab_size::Int)\n\nConstructs a Tokenizer by loading the vocabulary from a file in the llama2.c format. The vocabulary size must be known from the config.\n\nllama2.c correspondence: build_tokenizer (l. 385)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.Transformer","page":"Home","title":"Llama2.Transformer","text":"A transformer model, consisting of a config, weights, and a run state.\n\nllama2.c correspondence: Transformer (l. 67)\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.TransformerWeights","page":"Home","title":"Llama2.TransformerWeights","text":"Weights for the Llama2 transformer model.\n\nllama2.c correspondence: TransformerWeights (l. 29)\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.TransformerWeights-Tuple{Config}","page":"Home","title":"Llama2.TransformerWeights","text":"TransformerWeights(config::Config)\n\nInitialize transformer weight matrices based on Config.\n\nllama2.c correspondence: memorymapweights (l. 111)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.decode-Tuple{Tokenizer, Int64, Int64}","page":"Home","title":"Llama2.decode","text":"decode(tokenizer::Tokenizer, prev_token::Int32, token::Int32)\n\nDecodes a token index to a string. If the previous token is BOS, leading spaces are removed. Token indices are 1-based (different to the 0-based system in the llama2.c).\n\nllama2.c correspondence: decode (l. 418)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.encode","page":"Home","title":"Llama2.encode","text":"Encode a string text using the tokenizer.  Optional EOS token can be added. Encoded text can be decoded with the decode function.\n\nToken indices are 1-based (different to the 0-based system in the llama2.c).\n\nllama2.c correspondence: encode (l. 452)\n\n\n\n\n\n","category":"function"},{"location":"#Llama2.forward!-Tuple{Transformer, Int64, Int64}","page":"Home","title":"Llama2.forward!","text":"forward!(transformer::Transformer, token::Int, pos::Int)::Array{Float32}\n\nA single complete transformer forward pass for input token token at position pos, returning the output logits. pos is one-based, i.e. 1 <= pos <= seq_len. This modifies the RunState of the transformer.\n\nllama2.c correspondence: forward (l. 231)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.generate","page":"Home","title":"Llama2.generate","text":"function generate(\nmodel::Transformer,\ntokenizer::Tokenizer,\nsampler::Sampler,\nprompt::String,\nextend::Bool=true,\nverbose::Bool=true,\ndisplay_output::Bool=true,\ndisplay_prompt::Bool=true,\n\n)\n\nGenerate a sequence based on a given language model, tokenizer, sampler and prompt.\n\n\n\n\n\n","category":"function"},{"location":"#Llama2.read_karpathy-Tuple{String}","page":"Home","title":"Llama2.read_karpathy","text":"read_karpathy(file_path::String)\n\nReads Config and TransformerWeights from a Karpathy binary file, as defined in llama2.c.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.read_karpathy_weights-Tuple{Config, IOStream}","page":"Home","title":"Llama2.read_karpathy_weights","text":"read_karpathy_weights(config::Config, file::IOStream)\n\nReads TransformerWeights from a Karpathy binary file, as defined in llama2.c. The function assumes that the provided IOStream is already pointing to the beginning of the weights section.\n\nThe classifier weights are always assumed to be identical to the token_embedding_table because the config is guaranteed to have positive vocab_size, meaning that the weights are shared.\n\nllama2.c correspondence: memorymapweights (l. 111)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.rmsnorm-Tuple{Vector{Float32}, Vector{Float32}}","page":"Home","title":"Llama2.rmsnorm","text":"rmsnorm(x::Vector{Float32}, weight::Vector{Float32})\n\nCalculate the root mean square norm of a vector.  Reference in llama2.c lines 182-195\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.sample_argmax-Tuple{Vector{Float32}}","page":"Home","title":"Llama2.sample_argmax","text":"sample_argmax(logits::Vector{Float32})\n\nReturn the index that has the highest probability\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.sample_mult-Tuple{Vector{Float32}, Float32}","page":"Home","title":"Llama2.sample_mult","text":"sample_mult(probabilities::Vector{Float32}, coin::Float32)\n\nSample index from probabilities (they must sum to 1!). Coin is a random number in [0, 1). Find the index that coin falls into.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.sample_topp-Tuple{Vector{Float32}, Float32, Float32}","page":"Home","title":"Llama2.sample_topp","text":"sample_topp(probabilities::Vector{Float32}, topp::Float32, coin::Float32)\n\nTop-p sampling (or \"nucleus sampling\") samples from the smallest set of tokens that exceed probability topp. This way we never sample tokens that have very low probabilities and are less likely to go \"off the rails\". Coin is a random number in [0, 1)\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.softmax-Tuple{Vector{Float32}}","page":"Home","title":"Llama2.softmax","text":"softmax(x::Vector{Float32})\n\nCalculate the softmax of a vector.  Reference in llama2.c lines 197-215\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.swiglu-Tuple{Vector{Float32}, Vector{Float32}}","page":"Home","title":"Llama2.swiglu","text":"swiglu(x::Vector{Float32}, x2::Vector{Float32})\n\nActivation function that combines GLU and Swish functions. \n\nswiglu(x x_2) = x * x_2 * sigmoid(x)\n\nReference in llama2.c lines 338-345\n\n\n\n\n\n","category":"method"}]
}
